var(B)
C <- c(24,36,28,28,33)
mean(C)
sum(C)
var(C)
D <- c(20,32,38,28,25)
mean(D)
sum(C)
sum(D)
var(D)
aov(A~B~C~D)
aov(A,B,C,D)
num4 <- data.table(a = A, b = B, c = C)
num4 <- data.table(A,B,C)
num4 <- data(A,B,C,D)
sd(A)
sd(B)
sd(C)
sd(D)
num5 <- read.csv(C:/Users/Ripti/Desktop/num5.csv)
num5 <- read.csv(c:/Users/Ripti/Desktop/num5.csv)
num5 <- read.csv(c:Users/Ripti/Desktop/num5.csv)
num5 <- read.csv(c:\Users/Ripti/Desktop/num5.csv)
num5 <- read.csv(c:/Users/Ripti/Desktop/num5.csv)
num5 <- read.csv("C:/Users/Ripti/Desktop/num5.csv")
num5
num5$n(C)
num5$n$C
num5$n
num5$n(1)
num5$n[1]
mean = sum(num5$n*num5$mean)/sum(num5$n)
mean
MSb = sum(num5$n*(num5$mean-mean)^2)/4
MSb
MSw = (sum(num5$n-1)(num5$s)^2)/(sum(num5$n)-5)
MSw = (sum((num5$n)-1)(num5$s)^2)/(sum(num5$n)-5)
MSw = (sum((num5$n)-1)*(num5$s)^2)/(sum(num5$n)-5)
MSw
mean(MSw)
MSw = mean((sum((num5$n)-1)*(num5$s)^2)/(sum(num5$n)-5))
MSw
F = MSb/MSw
F
A <- c(2.92,4.69,1.88,4.89,5.35,5.81,3.81,5.55)
B <- c(1.84,3.44,.95,3.69,4.26,4.95,3.18,4.47)
AB <- c(A,B)
mean(A)
mean(B)
mean(AB)
SST = sum((AB-mean(AB))^2)
SST
SSr = (length(A)*(mean(A)-mean(AB)^2))+(length(B)*(mean(B)-mean(AB)^2))
SSr
SSr = (length(A)*(mean(A)-mean(AB))^2)+(length(B)*(mean(B)-mean(AB))^2)
SSr
Err = SST-SSr
Err
DFr = 2-1
DFr
DFsse = 16-2
DFsse
DFsst = 16-1
DFsst
MST = SST / DF
MST = SST / DFsst
MST
MSTr = SSr / DFr
MSTr
MSer = SSe/DFsse
MSer
SSe
MSer = Err / DFsse
MSer
F = MSTr/MSer
F
var.test(A,B)
t.test(A,B)
t.test(A,B, paired=true)
t.test(A,B, paired=TRUE)
num7 <- read.csv("C:/Users/Ripti/Desktop/num7.csv")
num7
View(num7)
sum(num7$X5)
sum(num7$X10)
sum(num7$X15)
sum(num7$X20)
sum(num7)
sum(num7$X20)+sum(num7$X15)+sum(num7$X10)+sum(num7$X5)
SSTr = 292^2/5+287^2/5+218^2/5+220^2/5-1017^2/20
SSTr
num7 <- read.csv("C:/Users/Ripti/Desktop/num7.csv")
SSTr = 292^2/5+287^2/5+218^2/5+210^2/5-1017^2/20
SSTr
SSTr = 292^2/5+287^2/5+218^2/5+210^2/5-1007^2/20
SSTr
SSE = sum((num7$x5)^2)+sum((num7$x10)^2)+sum((num7$x15)^2)+sum((num7$x20)^2)+1007^2/20
SSE
SSE = sum((num7$x5)^2)+sum((num7$x10)^2)+sum((num7$x15)^2)+sum((num7$x20)^2)-1007^2/20
SSE
SSE = sum((num7$x5)^2)+sum((num7$x10)^2)+sum((num7$x15)^2)+sum((num7$x20)^2)
SSE
sum(num7)^2
sum(num7$X5)^2
sum((num7$X5)^2)
sum((num7$X5)^2)+sum((num7$X10)^2)+sum((num7$X15)^2)+sum((num7$X20)^2)
sum((num7$X5)^2)+sum((num7$X10)^2)+sum((num7$X15)^2)+sum((num7$X20)^2)-10007^2/20
sum((num7$X5)^2)+sum((num7$X10)^2)+sum((num7$X15)^2)+sum((num7$X20)^2)-1007^2/20
SSE = sum((num7$X5)^2)+sum((num7$X10)^2)+sum((num7$X15)^2)+sum((num7$X20)^2)-1007^2/20- SSTr
SSE
MSSTr = SSTr/3
MSSTr
MSSe = SSE/16
MSSe
F = MSSTr/MSSE
F = MSSTr/MSSe
F
mean(num7$X5)
mean(num7$X10)
mean(num7$X15)
mean(num7$X20)
t.test(num7)
t.test(num7, paired=TRUE)
setwd("C:/Users/Ripti/Dropbox/Peoples/CSS143/Text-Mining-Sentiment-Analysis/02_DataHarvesting")
setup_twitter_oauth(key, secret, atoken, asecret)
library(twitteR)
library(ROAuth)
library(RCurl)
library(httr)
library(stringr)
library(plyr)
library(dplyr)
library(tm)
key="baIhzmVzumgOLAk0NQJPzInwm"
secret="ibg1gkL5ubICCQlk8kfoXPSqaLJYr6RnkE05zqkU9thHEJKf0Q"
atoken =  "931541622180929537-9VLB6EKwjFhAi9GqGmpOHj2CRwMhhEz"
asecret = "wplG3WaW03sevXgAqeaPd6bSmRDIKPMAujmJh9CHCnEHM"
setup_twitter_oauth(key, secret, atoken, asecret)
library("stringr")
library("plyr")
sentimentfun = function(tweettext, pos, neg, .progress='non')
{
# Parameters
# tweettext: vector of text to score
# pos: vector of words of postive sentiment
# neg: vector of words of negative sentiment
# .progress: passed to laply() 4 control of progress bar
# create simple array of scores with laply
scores = laply(tweettext,
function(singletweet, pos, neg)
{
# remove punctuation - using global substitute
singletweet = gsub("[[:punct:]]", "", singletweet)
# remove control characters
singletweet = gsub("[[:cntrl:]]", "", singletweet)
# remove digits
singletweet = gsub("\\d+", "", singletweet)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
singletweet = sapply(singletweet, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(singletweet, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos)
neg.matches = match(words, neg)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos, neg, .progress=.progress )
# data frame with scores for each sentence
sentiment.df = data.frame(text=tweettext, score=scores)
return(sentiment.df)
}
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
neg2 = c(neg, "bearish", "fraud"); tail(neg2)
scores = sentimentfun(tweettext, pos, neg, .progress='text')
tweets = searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="34.052,-118.244,200mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Apple Iphone",
city = "Los Angeles", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "apple_langeles.csv")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="40.713,-74.006,200mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Apple Iphone",
city = "New York", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "apple_newyork.csv")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="30.267,-97.743,200mi",
since = "2017-12-04")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="30.267,-97.743,400mi",
since = "2017-12-04")
#   Austin
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="30.267,-97.743,500mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Apple Iphone",
city = "Austin", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "apple_austin.csv")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="47.606,-122.332,200mi",
since = "2017-12-04")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="47.606,-122.332,500mi",
since = "2017-12-04")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="47.606,-122.332,1000mi",
since = "2017-12-04")
tweets =searchTwitter("apple+iphone", n=2000,
lang="en",
geocode="47.606,-122.332,500mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Apple Iphone",
city = "Seattle", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "apple_seattle.csv")
tweets = searchTwitter("samsung+galaxy", n=2000,
lang="en",
geocode="34.052,-118.244,200mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
# getting the opinion lexicons from working directory
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
neg2 = c(neg, "bearish", "fraud"); tail(neg2)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Samsung Galaxy",
city = "Los Angeles", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "samsung_losangeles.csv")
tweets =searchTwitter("samsung+galaxy", n=2000,
lang="en",
geocode="40.713,-74.006,200mi",
since = "2017-12-04")
tweets =searchTwitter("samsung+galaxy", n=2000,
lang="en",
geocode="40.713,-74.006,200mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
# getting the opinion lexicons from working directory
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
neg2 = c(neg, "bearish", "fraud"); tail(neg2)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Samsung Galaxy",
city = "New York", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "samsung_newyork.csv")
tweets =searchTwitter("samsung+galaxy", n=2000,
lang="en",
geocode="30.267,-97.743,500mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
# getting the opinion lexicons from working directory
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
neg2 = c(neg, "bearish", "fraud"); tail(neg2)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Samsung Galaxy",
city = "Austin", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "samsung_austin.csv")
tweets =searchTwitter("samsung+galaxy", n=2000,
lang="en",
geocode="47.606,-122.332,1000mi",
since = "2017-12-04")
tweets =searchTwitter("samsung+galaxy", n=2000,
lang="en",
geocode="47.606,-122.332,500mi",
since = "2017-12-04")
# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
## first cleaning stage
tweettext=lapply(tweettext, function(x) iconv(x, "latin1",
"ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)
# getting the opinion lexicons from working directory
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")
neg2 = c(neg, "bearish", "fraud"); tail(neg2)
## apply function score.sentiment
scores = sentimentfun(tweettext, pos, neg, .progress='text')
## extracting further elements (besides text) for the export csv
tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))
isretweet=sapply(tweets, function(x) x$getIsRetweet())
retweetcount=sapply(tweets, function(x) x$getRetweetCount())
favoritecount=sapply(tweets, function(x) x$getFavoriteCount())
## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
date=tweetdate,
isretweet=isretweet,
retweetcount=retweetcount,
favoritecount=favoritecount,
score = scores$score,
product = "Samsung Galaxy",
city = "Seattle", country = "USA"))
## remove duplicates
data2 = duplicated(data[,1])
data$duplicate = data2
## create file to wd
write.csv(data, file= "samsung_seattle.csv")
